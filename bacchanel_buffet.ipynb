{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import operator\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.classify import textcat\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "# nltk.download('punkt');\n",
    "# nltk.download('averaged_perceptron_tagger');\n",
    "# nltk.download('crubadan');\n",
    "# nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "\n",
    "df = pd.read_csv('Bacchanal-Buffet-reviews.csv', parse_dates=['date'], lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove reviews that are not written in English\n",
    "\n",
    "def is_english(s):\n",
    "    # Texts that include words written in French (e.g., crème brûlée) \n",
    "    # are not classified as written in English\n",
    "    return s.isascii()\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "i_texts_english = [i for i, text in enumerate(texts) if is_english(text)]\n",
    "df_english = df.iloc[i_texts_english, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['getting', 'food', 'poisoning', 'palms', 'hotel', 'scared', 'eat', 'buffets', 'figured', 'high', 'price', 'tag', 'positive', 'reviews', 'etc', 'worth', 'chance', 'really', 'glad', 'gave', 'try', 'btw', 'uploaded', 'collage', 'things', 'ate', 'seafood', 'line', 'far', 'longest', 'would', 'recommend', 'showing', 'heels', 'youre', 'female', 'feet', 'killing', 'line', 'door', 'line', 'get', 'sat', 'seafood', 'line', 'totally', 'worth', 'though', 'prime', 'rib', 'best', 'ive', 'ever', 'loved', 'sweet', 'potato', 'tots', 'even', 'pho', 'music', 'great', 'server', 'alma', 'older', 'gentleman', 'mustache', 'attentive', 'delightful', 'return', 'next', 'trip', 'comfortable', 'shoes', 'horrible', 'visit', 'palms', 'non', 'stop', 'issues', 'matter', 'hours', 'establishment', 'truly', 'high', 'light', 'trip', 'thank', 'exquisite', 'dinner']\n"
     ]
    }
   ],
   "source": [
    "## Clean the text data\n",
    "\n",
    "# Stemming?\n",
    "# Lemmatization?\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean_text(text, K=1, stemming=False):\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "\n",
    "    # Remove words that are not purely comprised of alphabetical characters\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    \n",
    "    # Transform the text into lowercase letters\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # Stem the words\n",
    "    if stemming:\n",
    "        tokens_stemmed = [ps.stem(w) for w in tokens]\n",
    "        tokens = list(set(tokens_stemmed))\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    # Remove words that contain fewer than K+1 characters\n",
    "    tokens = [w for w in tokens if len(w) > K]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "texts_english = df_english['text'].tolist()\n",
    "texts_tokenized = [clean_text(text, K=2) for text in texts_english]\n",
    "\n",
    "print(texts_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21043\n",
      "[('buffet', 13233), ('food', 11308), ('good', 6986), ('line', 5246), ('get', 5183), ('crab', 5018), ('vegas', 4911), ('time', 4788), ('wait', 4712), ('like', 4331), ('best', 3999), ('one', 3991), ('worth', 3723), ('seafood', 3632), ('great', 3572), ('legs', 3421), ('would', 3413), ('place', 3295), ('really', 3262), ('back', 3179), ('buffets', 3002), ('dessert', 2964), ('price', 2871), ('bacchanal', 2784), ('try', 2769), ('also', 2753), ('station', 2695), ('dinner', 2686), ('much', 2679), ('everything', 2662), ('quality', 2654), ('dont', 2625), ('service', 2614), ('selection', 2547), ('eat', 2456), ('even', 2437), ('fresh', 2422), ('got', 2410), ('long', 2371), ('better', 2280), ('come', 2249), ('went', 2242), ('didnt', 2205), ('well', 2169), ('definitely', 2126), ('section', 2014), ('desserts', 1958), ('around', 1942), ('pretty', 1897), ('variety', 1887)]\n",
      "[('feelstastes', 1), ('awed', 1), ('fights', 1), ('buffetpricey', 1), ('sugarlessfatfree', 1), ('ribetc', 1), ('electricity', 1), ('monet', 1), ('sammys', 1), ('birthdayleft', 1), ('fofo', 1), ('abiding', 1), ('oomph', 1), ('huuugge', 1), ('sushisushi', 1), ('bellyall', 1), ('plusi', 1), ('paprika', 1), ('andrew', 1), ('redonkuless', 1), ('restaurantquality', 1), ('assorment', 1), ('opg', 1), ('phobic', 1), ('whoda', 1), ('vying', 1), ('hoarding', 1), ('sistas', 1), ('brothas', 1), ('cluless', 1), ('labelling', 1), ('fainting', 1), ('learnt', 1), ('therethere', 1), ('wantfrom', 1), ('recline', 1), ('spacea', 1), ('whisk', 1), ('lionscold', 1), ('swingandamiss', 1), ('baconregular', 1), ('eggsmexican', 1), ('btwthe', 1), ('maps', 1), ('orienteering', 1), ('freshen', 1), ('compass', 1), ('dreck', 1), ('omit', 1)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create a vocabulary\n",
    "\n",
    "vocabulary = Counter()\n",
    "\n",
    "for tokens in texts_tokenized:\n",
    "    vocabulary.update(tokens)\n",
    "\n",
    "# Print the size of the vocabulary\n",
    "print(len(vocabulary))\n",
    "\n",
    "# Print the top words in the vocabulary\n",
    "print(vocabulary.most_common(50))\n",
    "\n",
    "# Print the least common words in the vocabulary\n",
    "print(vocabulary.most_common()[:-50:-1])\n",
    "\n",
    "_, ax = plt.subplots();\n",
    "ax.hist(np.log(list(vocabulary.values())));\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['getting', 'food', 'poisoning', 'hotel', 'eat', 'buffets', 'figured', 'high', 'price', 'tag', 'positive', 'reviews', 'etc', 'worth', 'chance', 'really', 'glad', 'gave', 'try', 'btw', 'things', 'ate', 'seafood', 'line', 'far', 'would', 'recommend', 'youre', 'get', 'sat', 'totally', 'though', 'prime', 'rib', 'best', 'ive', 'ever', 'loved', 'sweet', 'potato', 'tots', 'even', 'pho', 'music', 'great', 'server', 'attentive', 'return', 'next', 'trip']\n",
      "1577\n"
     ]
    }
   ],
   "source": [
    "## Remove words that have low occurrence in the corpus\n",
    "\n",
    "min_occurance = 50\n",
    "tokens = [k for k, c in vocabulary.items() if c >= min_occurance]\n",
    "\n",
    "print(tokens[:50])\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>getting</th>\n",
       "      <th>food</th>\n",
       "      <th>poisoning</th>\n",
       "      <th>hotel</th>\n",
       "      <th>eat</th>\n",
       "      <th>buffets</th>\n",
       "      <th>figured</th>\n",
       "      <th>high</th>\n",
       "      <th>price</th>\n",
       "      <th>tag</th>\n",
       "      <th>...</th>\n",
       "      <th>snails</th>\n",
       "      <th>bachannal</th>\n",
       "      <th>banana</th>\n",
       "      <th>lover</th>\n",
       "      <th>speak</th>\n",
       "      <th>mark</th>\n",
       "      <th>standards</th>\n",
       "      <th>treats</th>\n",
       "      <th>overhyped</th>\n",
       "      <th>picked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9688 rows × 1577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      getting  food  poisoning  hotel  eat  buffets  figured  high  price  \\\n",
       "0           1     1          1      1    1        1        1     2      1   \n",
       "1           0     0          0      0    0        0        0     0      0   \n",
       "2           0     1          0      0    0        0        0     0      0   \n",
       "3           0     2          0      0    0        0        0     0      0   \n",
       "4           0     1          0      0    0        0        0     0      0   \n",
       "...       ...   ...        ...    ...  ...      ...      ...   ...    ...   \n",
       "9683        0     2          0      0    0        0        0     0      0   \n",
       "9684        0     0          0      0    0        0        0     0      0   \n",
       "9685        1     2          0      0    0        0        0     1      2   \n",
       "9686        0     0          0      0    1        0        0     0      0   \n",
       "9687        0     1          0      0    0        0        0     0      1   \n",
       "\n",
       "      tag  ...  snails  bachannal  banana  lover  speak  mark  standards  \\\n",
       "0       1  ...       0          0       0      0      0     0          0   \n",
       "1       0  ...       0          0       0      0      0     0          0   \n",
       "2       0  ...       0          0       0      0      0     0          0   \n",
       "3       0  ...       0          0       0      0      0     0          0   \n",
       "4       0  ...       0          0       0      0      0     0          0   \n",
       "...   ...  ...     ...        ...     ...    ...    ...   ...        ...   \n",
       "9683    0  ...       0          0       0      0      0     0          0   \n",
       "9684    0  ...       0          0       0      0      0     0          0   \n",
       "9685    0  ...       0          0       0      0      0     0          0   \n",
       "9686    0  ...       0          0       0      0      0     0          0   \n",
       "9687    0  ...       0          0       0      0      0     0          0   \n",
       "\n",
       "      treats  overhyped  picked  \n",
       "0          0          0       0  \n",
       "1          0          0       0  \n",
       "2          0          0       0  \n",
       "3          0          0       0  \n",
       "4          0          0       0  \n",
       "...      ...        ...     ...  \n",
       "9683       0          0       0  \n",
       "9684       0          0       0  \n",
       "9685       0          0       0  \n",
       "9686       0          0       0  \n",
       "9687       0          0       0  \n",
       "\n",
       "[9688 rows x 1577 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a term-document matrix\n",
    "\n",
    "# Create a dictionary from the most common tokens in the vocabulary\n",
    "vocabulary_final = dict(zip(tokens, range(len(tokens))))\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=clean_text, vocabulary=vocabulary_final)\n",
    "X = vectorizer.fit_transform(texts_english)\n",
    "\n",
    "# Create DataFrame\n",
    "df_tdm = pd.DataFrame(X.toarray().transpose(), index = vectorizer.get_feature_names()).T\n",
    "\n",
    "df_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data to files\n",
    "\n",
    "df_tdm.to_csv('X.csv', index=False)\n",
    "df_english['useful'].to_csv('Y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD ###\n",
    "\n",
    "# Find unique words in all reviews\n",
    "\n",
    "unique_words = set()\n",
    "\n",
    "texts = df_english['text'].tolist()\n",
    "\n",
    "for text in texts:\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    words = [word for word in words if word.isalpha()]  # Remove words that contain numbers\n",
    "    unique_words.update(words)\n",
    "\n",
    "print('There are ' + str(len(unique_words)) + ' unique words.')\n",
    "\n",
    "# Count the number of occurences of each unique word\n",
    "\n",
    "words_freqs = dict.fromkeys(unique_words, 0)\n",
    "\n",
    "for text in texts:\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    # Remove words that contain numbers\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    for word in words:\n",
    "        words_freqs[word] += 1\n",
    "\n",
    "words_freqs_sorted = sorted(words_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Remove words that should not influence the meaning of the text\n",
    "\n",
    "relevant_words = []\n",
    "\n",
    "for word, _ in words_freqs_sorted:\n",
    "    token = nltk.word_tokenize(word)\n",
    "    tag = nltk.pos_tag(token)[0][1]\n",
    "    if tag.startswith('J') or tag.startswith('N') or tag.startswith('RB') or tag.startswith('V'):\n",
    "        relevant_words.append(word)\n",
    "\n",
    "print('There are ' + str(len(relevant_words)) + ' meaningful words.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
